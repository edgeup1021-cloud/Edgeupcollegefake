from ..apps import Models
import json
import asyncio
from ..config import Config
import requests
import tempfile
import io
from typing import List, Dict, Optional
from bs4 import BeautifulSoup
from PyPDF2 import PdfReader
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from ..utils.loggers import setup_logger
from asgiref.sync import sync_to_async
logger = setup_logger("django_logger")


async def generate_mcqs(question_type, meta_data=None, total_questions =None):
    """
    Generate multiple-choice questions from a reference document with guaranteed explanation.
    """
    logger.info(f"Starting {question_type} generation process")
    
    try:
        logger.debug("Configuring Gemini API")
        text_content = ""
        if meta_data.get("url") != "":
            # Make the request and get headers to check content type
            response = requests.get(meta_data["url"], stream=True)
            response.raise_for_status()
            
            # Check the Content-Type header first (most reliable)
            content_type = response.headers.get('Content-Type', '').lower()
            url_lower = meta_data["url"].lower()
            
            is_pdf = (
                'application/pdf' in content_type or
                url_lower.endswith('.pdf') or
                # Handle PDF URLs with query parameters
                '.pdf?' in url_lower or
                '.pdf#' in url_lower
            )
            
            if is_pdf:
                logger.info("Processing PDF content")
                pdf_file = io.BytesIO(response.content)
                reader = PdfReader(pdf_file)
                with tempfile.TemporaryFile(mode='w+', encoding='utf-8') as tmp:
                    for page in reader.pages:
                        extracted = page.extract_text()
                        if extracted:
                            tmp.write(extracted + "\n")
                    tmp.seek(0)
                    text_content = tmp.read(100000).strip()
            else:
                logger.info("Processing HTML content")
                # If HTML content or other web content
                soup = BeautifulSoup(response.content, 'html.parser')
                text_content = soup.get_text()[:100000].strip()


        match question_type:
            case "mcq":
                # Fixed: Replaced undefined mock_mcq_prompt with mcq_prompt
                # College-focused MCQ generation with education_level parameter
                prompt = Config.mcq_prompt.format(
                    User_prompt="",
                    num_questions=total_questions,
                    subject=meta_data.get("subject", "General"),
                    education_level=meta_data.get("education_level", "undergraduate"),
                    topic=meta_data.get("topic", "General Knowledge"),
                    subtopic=meta_data.get("subtopic", ""),
                    focus_instruction="covering broad general knowledge topics",
                    question_focus="about general knowledge",
                    explanation_context="relating to general awareness",
                    combined_content=meta_data.get("content", ""),
                    subtopic_context="",
                    topic_id=meta_data.get("topic_id", ""),
                    question_type="general",
                    mcq_type=0
                )

            case 'descriptive':
                # Fixed: Replaced undefined mock_descriptive_prompt with descriptive_prompt
                # College-focused descriptive question generation with education_level parameter
                prompt = Config.descriptive_prompt.format(
                    User_prompt="",
                    num_questions=total_questions,
                    subject=meta_data.get("subject", "General"),
                    topic_id=meta_data.get("topic_id", ""),
                    topic=meta_data.get("topic", "General Knowledge"),
                    subtopic=meta_data.get("subtopic", ""),
                    focus_instruction="covering broad general knowledge topics",
                    question_focus="about general knowledge",
                    subtopic_context="",
                    explanation_context="relating to general awareness",
                    combined_content=meta_data.get("content", ""),
                    education_level=meta_data.get("education_level", "undergraduate")
                )
                   
        try:
 
                logger.info(f"Sending request to Gemini API {question_type}")
                response =Models.model.generate_content(prompt)
                    
                logger.info(f"questions generated by gemini for {question_type}")
                mcqs = response.text.strip()
                logger.debug(f"Raw response from Gemini API: {mcqs}")
             

                if not mcqs:
                    logger.warning("Empty response received from Gemini API")
                    raise ValueError("Empty response from Gemini API")
                
                if"question" not in  mcqs:
                    logger.warning("Empty response received from Gemini API")
                    raise ValueError("Empty response from Gemini API")
                
                logger.info(f"Successfully received {question_type} output from Gemini API")
                mcqs = (mcqs[mcqs.index("["):mcqs.rindex("]")+1])
                parsed_mcqs = json.loads(mcqs)
                return parsed_mcqs

        except Exception as e:
                logger.error(f"API Error", exc_info=True)
                raise


    except Exception as e:
        logger.critical(f"Critical error in MCQ generation: {e}", exc_info=True)
        raise


async def generate_mcqs_service(validated_data):
    """Service function to generate MCQs."""
    logger.info("MCQ generation service called")
    meta_data = validated_data.get('meta_data')
    configuration = validated_data.get('configuration')
    total_questions = configuration["number_of_questions"]

    pdf_path = validated_data['path']
    meta_data["url"] = ""
    
    logger.debug(f"Service parameters: PDF={pdf_path}, config={configuration}")

    mcqs = await  generate_mcqs(
        meta_data=meta_data,  
        total_questions=total_questions,
        question_type = meta_data["question_type"]    
    )
    
    return mcqs

MAX_CONCURRENT_REQUESTS = 10

async def generate_structured_psychometric_service(data):
    """
    Modified service function to generate structured psychometric questions
    with parallel processing across topics.
    """
    logger.info("Structured psychometric service called with parallel processing")
    try:
        # Configure Gemini API
        logger.debug("Configuring Gemini API")
        
        # Create semaphore in the current event loop
        semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
        
        # Extract configuration
        configuration = data.get('configuration', {})
        sections = data.get('sections', [])
        
        logger.debug(f"Service input: {len(sections)} sections, config: {configuration}")

        # Collect all topic generation tasks
        topic_tasks = []
        section_topic_mapping = []

        for section_idx, section in enumerate(sections):
            section_name = section.get('section_name', '')
            section_id = section.get('section_id',"")
            no_of_questions = section.get("number_of_questions","")
            
            if not section_name and not section_id:
                logger.warning(f"Skipping section at index {section_idx}: missing section_name")
                continue  # Skip if section_name is empty
            
            logger.info(f"Processing section: {section_name}")

            for subject_idx, subject_data in enumerate(section.get('subjects', [])):
                subject_name = subject_data.get('subject', '')
                subject_id = subject_data.get('subject_id',"")
                if not subject_name:
                    logger.warning(f"Skipping subject at index {subject_idx} in section {section_name}: missing subject name")
                    continue  # Skip if subject_name is empty

                logger.info(f"Processing subject: {subject_name} in section {section_name}")

                for topic_idx, topic_data in enumerate(subject_data.get('topics', [])):
                    topic_name = topic_data.get('topic_name', '')
                    topic_id = topic_data.get('topic_id',"")
                    topic_config = topic_data.get('configuration', {})

                    if not topic_name:
                        logger.warning(f"Skipping topic at index {topic_idx} in subject {subject_name}: missing topic name")
                        continue  # Skip if topic_name is empty

                    logger.info(f"Creating task for topic: {topic_name} in subject {subject_name}")
                    
                    # Create async task for this topic
                    task = generate_topic_questions_with_semaphore(
                        section_name=section_name,
                        subject_name=subject_name,
                        topic_name=topic_name,
                        configuration=topic_config,
                        subject_id=subject_id,
                        topic_id=topic_id,
                        semaphore=semaphore  # Pass semaphore to the function
                    )
                    topic_tasks.append(task)
                    
                    # Store mapping to reconstruct response structure
                    section_topic_mapping.append({
                        'section_idx': section_idx,
                        'section_name': section_name,
                        'section_id': section_id,
                        'no_of_questions': no_of_questions,
                        'task_idx': len(topic_tasks) - 1
                    })

        # Execute all tasks in parallel
        logger.info(f"Executing {len(topic_tasks)} topic tasks in parallel")
        topic_results = await asyncio.gather(*topic_tasks, return_exceptions=True)
        
        # Reconstruct the response structure
        result = []
        sections_dict = {}
        
        for mapping in section_topic_mapping:
            section_key = f"{mapping['section_idx']}_{mapping['section_name']}"
            
            # Initialize section if not exists
            if section_key not in sections_dict:
                sections_dict[section_key] = {
                    "sectionName": mapping['section_name'],
                    "sectionId": mapping['section_id'],
                    "no_of_questions": mapping['no_of_questions'],
                    "questions": []
                }
            
            # Get the result for this topic
            task_result = topic_results[mapping['task_idx']]
            
            # Handle exceptions
            if isinstance(task_result, Exception):
                logger.error(f"Error in task for topic: {task_result}")
                continue
            
            # Add questions to section
            if task_result:
                sections_dict[section_key]["questions"].extend(task_result)
        
        # Convert dict to list maintaining order
        result = list(sections_dict.values())

        logger.info(f"Completed structured psychometric service with parallel processing")
        return result

    except Exception as e:
        logger.critical(f"Error in structured psychometric service: {str(e)}", exc_info=True)
        raise

async def generate_topic_questions_with_semaphore(section_name, subject_name, topic_name, configuration, topic_id, subject_id, semaphore):
    """
    Wrapper function to control concurrent API calls using semaphore.
    """
    async with semaphore:
        return await generate_topic_questions(
            section_name, subject_name, topic_name, configuration, topic_id, subject_id
        )

async def generate_topic_questions(section_name, subject_name, topic_name, configuration, topic_id, subject_id):
    """
    Generate questions for a specific topic using the Gemini model.
    (Keep your existing implementation, just ensure it's properly async)
    """
    logger.info(f"Generating questions for topic: {topic_name} (subject: {subject_name}, section: {section_name})")
    num_questions = configuration.get('number_of_questions', 5)
    num_options = configuration.get('number_of_options', 4)
    difficulty = configuration.get('difficulty_level', 'medium')
    marks = configuration.get('marks_weightage', 1)
    
    logger.debug(f"Topic configuration: questions={num_questions}, options={num_options}, difficulty={difficulty}, marks={marks}")

    prompt = Config.psychometric_prompt.format(
        section_name=section_name,
        subject_name=subject_name,
        topic_name=topic_name,
        difficulty=difficulty,
        subject_id=subject_id,
        topic_id=topic_id,
        num_questions=num_questions,
        num_options=num_options,
        marks=marks
    )

    try:
        logger.info(f"Sending request to Gemini API for topic: {topic_name}")
        response = await asyncio.to_thread(Models.model.generate_content, prompt)
        questions_output = response.text.strip()
        logger.info(f"Response for {topic_name}: {questions_output}")
       
        if not questions_output:
            logger.warning(f"Empty response from Gemini API for topic: {topic_name}")
            raise ValueError("Empty response from Gemini API")
        
        return json.loads(questions_output[questions_output.index("["):questions_output.rindex("]")+1])
        
    except Exception as e:
        logger.error(f"Error generating questions for topic {topic_name}: {e}", exc_info=True)
        return []  # Return empty list on error


def plag_check(text):
    logger.info("Checking for plagiarism...")
    url = Config.PLAGARISM_URL
    text = text.ljust(100)

    payload = {
        "text": text,
    }

    headers = {
        "Authorization": Config.PLAGARISM_API_KEY,
        "Content-Type": "application/json"
    }

    # Setup retry strategy
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,  # Wait 1s, then 2s, then 4s (exponential backoff)
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["POST"],
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)

    session = requests.Session()
    session.mount("http://", adapter)
    session.mount("https://", adapter)

    try:
        response = session.post(url, json=payload, headers=headers)
        logger.info("Response Received...")
        answer = response.json()
        if answer.get('result'):
            logger.info(f"Plagiarism checked...{answer.get('result')}")
            score = answer['result']['score']
            logger.info(f"Question: {text} Status: {score}")
            return score
    except requests.exceptions.RequestException as e:
        logger.error(f"Plagiarism API call failed after retries: {e}")

    logger.info("Plagiarism API is not working")
    return 2

# Utility functions (shared with tasks.py)
# NOTE: Exam-specific functions (get_priority_flags, get_vlp_flags) have been removed.
# These were used for competitive exam routing and are not needed for college system.


def extract_json_from_response(response: str) -> Optional[List[Dict]]:
    """Extract JSON array from response string."""
    try:
        if '[' in response and ']' in response:
            start_idx = response.index('[')
            end_idx = response.rindex(']') + 1
            json_str = response[start_idx:end_idx]
            return json.loads(json_str)
        return None
    except (json.JSONDecodeError, ValueError) as e:
        logger.error(f"Error parsing JSON from response: {e}")
        return None